{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision numpy scikit-image matplotlib tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFVtchkQAp51",
        "outputId": "8f28f26e-989f-4c2c-d009-ba41eee362ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.3)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.12.12)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# GMiSDE-Net\n",
        "# GammaMoE + CHSN + Implicit SDE\n",
        "# MNIST + Speckle (Gamma noise)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "IMG_SIZE = 32\n",
        "BATCH = 64\n",
        "EPOCHS = 10\n",
        "LR = 2e-4\n",
        "\n",
        "EPS = 1e-4\n",
        "GAMMA_K = 2.0\n",
        "NUM_EXPERTS = 4\n",
        "\n",
        "SAVE_DIR = \"./gmisde_results\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# DATASET: MNIST + GAMMA SPECKLE\n",
        "# ============================================================\n",
        "\n",
        "class MNISTSpeckle(Dataset):\n",
        "    def __init__(self, train=True):\n",
        "        tfm = T.Compose([\n",
        "            T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "            T.ToTensor()\n",
        "        ])\n",
        "        base = datasets.MNIST(\"./data\", train=train, download=True, transform=tfm)\n",
        "        self.samples = []\n",
        "\n",
        "        for img, _ in base:\n",
        "            clean = img.squeeze(0).clamp(EPS, 1.0)\n",
        "            gamma = torch.distributions.Gamma(GAMMA_K, GAMMA_K).sample(clean.shape)\n",
        "            noisy = (clean * gamma).clamp(EPS, 1.0)\n",
        "            self.samples.append((noisy, clean))\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, i): return self.samples[i]\n",
        "\n",
        "# ============================================================\n",
        "# CHSN EXPERT\n",
        "# ============================================================\n",
        "\n",
        "class CHSN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU()\n",
        "        )\n",
        "        self.mu = nn.Conv2d(64, 1, 3, padding=1)\n",
        "        self.sigma = nn.Conv2d(64, 1, 3, padding=1)\n",
        "        self.unc = nn.Conv2d(64, 1, 3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.enc(x)\n",
        "        mu = self.mu(h)\n",
        "        sigma = 0.1 * F.softplus(self.sigma(h)) + EPS\n",
        "        unc = torch.sigmoid(self.unc(h))\n",
        "        return mu, sigma, unc\n",
        "\n",
        "# ============================================================\n",
        "# GAMMA MIXTURE OF EXPERTS\n",
        "# ============================================================\n",
        "\n",
        "class GammaMoE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.router = nn.Conv2d(1, NUM_EXPERTS, 1)\n",
        "        self.experts = nn.ModuleList([CHSN() for _ in range(NUM_EXPERTS)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        weights = F.softmax(self.router(x), dim=1)\n",
        "\n",
        "        mu, sigma, unc = 0, 0, 0\n",
        "        for i, expert in enumerate(self.experts):\n",
        "            m, s, u = expert(x)\n",
        "            w = weights[:, i:i+1]\n",
        "            mu += w * m\n",
        "            sigma += w * s\n",
        "            unc += w * u\n",
        "\n",
        "        return mu, sigma, unc\n",
        "\n",
        "# ============================================================\n",
        "# IMPLICIT SDE HEAD\n",
        "# ============================================================\n",
        "\n",
        "class ImplicitSDE(nn.Module):\n",
        "    \"\"\"\n",
        "    Learns terminal solution:\n",
        "    x_T = x + f_theta(x, μ, σ)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 1, 3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mu, sigma):\n",
        "        inp = torch.cat([x, mu, sigma], dim=1)\n",
        "        delta = self.net(inp)\n",
        "        return (x + delta).clamp(EPS, 1.0)\n",
        "\n",
        "# ============================================================\n",
        "# FULL MODEL\n",
        "# ============================================================\n",
        "\n",
        "class GMiSDENet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.moe = GammaMoE()\n",
        "        self.sde = ImplicitSDE()\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, sigma, unc = self.moe(x)\n",
        "        return self.sde(x, mu * unc, sigma)\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING\n",
        "# ============================================================\n",
        "\n",
        "def train():\n",
        "    dataset = MNISTSpeckle(train=True)\n",
        "    loader = DataLoader(dataset, BATCH, shuffle=True)\n",
        "\n",
        "    model = GMiSDENet().to(DEVICE)\n",
        "    opt = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    print(\"\\nTraining GMiSDE-Net...\\n\")\n",
        "\n",
        "    for ep in range(EPOCHS):\n",
        "        total = 0\n",
        "        for noisy, clean in loader:\n",
        "            noisy = noisy.unsqueeze(1).to(DEVICE)\n",
        "            clean = clean.unsqueeze(1).to(DEVICE)\n",
        "\n",
        "            recon = model(noisy)\n",
        "\n",
        "            loss = (\n",
        "                F.mse_loss(recon, clean) +\n",
        "                0.2 * ((torch.log(recon) - torch.log(clean)) ** 2).mean()\n",
        "            )\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            total += loss.item()\n",
        "\n",
        "        print(f\"[Epoch {ep+1:02d}] Loss={total/len(loader):.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# ============================================================\n",
        "# EVALUATION\n",
        "# ============================================================\n",
        "\n",
        "def evaluate(model):\n",
        "    dataset = MNISTSpeckle(train=False)\n",
        "    psnr_list, ssim_list = [], []\n",
        "\n",
        "    print(\"\\nEvaluating...\\n\")\n",
        "\n",
        "    for i in range(10):\n",
        "        noisy, clean = dataset[i]\n",
        "        noisy = noisy.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "        clean = clean.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            recon = model(noisy)\n",
        "\n",
        "        cn = clean[0,0].cpu().numpy()\n",
        "        nn = noisy[0,0].cpu().numpy()\n",
        "        rn = recon[0,0].cpu().numpy()\n",
        "\n",
        "        p = peak_signal_noise_ratio(cn, rn, data_range=1.0)\n",
        "        s = structural_similarity(cn, rn, data_range=1.0)\n",
        "\n",
        "        psnr_list.append(p)\n",
        "        ssim_list.append(s)\n",
        "\n",
        "        fig, ax = plt.subplots(1,4, figsize=(12,3))\n",
        "        ax[0].imshow(cn, cmap=\"gray\"); ax[0].set_title(\"Clean\")\n",
        "        ax[1].imshow(nn, cmap=\"gray\"); ax[1].set_title(\"Noisy\")\n",
        "        ax[2].imshow(np.abs(nn-cn), cmap=\"hot\"); ax[2].set_title(\"Noise\")\n",
        "        ax[3].imshow(rn, cmap=\"gray\"); ax[3].set_title(f\"GMiSDE\\nPSNR={p:.2f}\")\n",
        "        for a in ax: a.axis(\"off\")\n",
        "        plt.savefig(f\"{SAVE_DIR}/sample_{i}.png\", dpi=150)\n",
        "        plt.close()\n",
        "\n",
        "    print(\"\\n=== RESULTS ===\")\n",
        "    print(f\"Avg PSNR: {np.mean(psnr_list):.2f}\")\n",
        "    print(f\"Avg SSIM: {np.mean(ssim_list):.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# MAIN\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = train()\n",
        "    evaluate(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K_SSXzoyYTy",
        "outputId": "dc061321-3094-46ad-d0fa-0e8ae2a6afee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 507kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.69MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.86MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training GMiSDE-Net...\n",
            "\n",
            "[Epoch 01] Loss=0.0641\n",
            "[Epoch 02] Loss=0.0425\n",
            "[Epoch 03] Loss=0.0393\n",
            "[Epoch 04] Loss=0.0352\n",
            "[Epoch 05] Loss=0.0301\n",
            "[Epoch 06] Loss=0.0262\n",
            "[Epoch 07] Loss=0.0237\n",
            "[Epoch 08] Loss=0.0209\n",
            "[Epoch 09] Loss=0.0188\n",
            "[Epoch 10] Loss=0.0171\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "\n",
            "=== RESULTS ===\n",
            "Avg PSNR: 26.22\n",
            "Avg SSIM: 0.9705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# GMiSDE-Net vs ID-CNN vs DnCNN\n",
        "# MNIST + Speckle (Gamma noise) — FULL VISUALIZATION\n",
        "# ============================================================\n",
        "\n",
        "import os, torch, numpy as np, matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "IMG_SIZE = 32\n",
        "BATCH = 64\n",
        "EPOCHS = 10\n",
        "LR = 2e-4\n",
        "\n",
        "EPS = 1e-4\n",
        "GAMMA_K = 2.0\n",
        "NUM_EXPERTS = 4\n",
        "\n",
        "SAVE_DIR = \"./gmisde_compare\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# DATASET\n",
        "# ============================================================\n",
        "\n",
        "class MNISTSpeckle(Dataset):\n",
        "    def __init__(self, train=True):\n",
        "        tfm = T.Compose([T.Resize((IMG_SIZE, IMG_SIZE)), T.ToTensor()])\n",
        "        base = datasets.MNIST(\"./data\", train=train, download=True, transform=tfm)\n",
        "        self.data = []\n",
        "\n",
        "        for img, _ in base:\n",
        "            clean = img.squeeze(0).clamp(EPS, 1.0)\n",
        "            gamma = torch.distributions.Gamma(GAMMA_K, GAMMA_K).sample(clean.shape)\n",
        "            noisy = (clean * gamma).clamp(EPS, 1.0)\n",
        "            self.data.append((noisy, clean))\n",
        "\n",
        "    def __len__(self): return len(self.data)\n",
        "    def __getitem__(self, i): return self.data[i]\n",
        "\n",
        "# ============================================================\n",
        "# BASELINES\n",
        "# ============================================================\n",
        "\n",
        "class IDCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,1,3,1,1)\n",
        "        )\n",
        "    def forward(self,x): return self.net(x).clamp(EPS,1)\n",
        "\n",
        "class DnCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,1,3,1,1)\n",
        "        )\n",
        "    def forward(self,x): return (x - self.net(x)).clamp(EPS,1)\n",
        "\n",
        "# ============================================================\n",
        "# PROPOSED MODEL: GMiSDE-Net\n",
        "# ============================================================\n",
        "\n",
        "class CHSN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Conv2d(1,32,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(32,64,3,1,1), nn.ReLU()\n",
        "        )\n",
        "        self.mu = nn.Conv2d(64,1,3,1,1)\n",
        "        self.sigma = nn.Conv2d(64,1,3,1,1)\n",
        "        self.unc = nn.Conv2d(64,1,3,1,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        h = self.enc(x)\n",
        "        mu = self.mu(h)\n",
        "        sigma = 0.1*F.softplus(self.sigma(h)) + EPS\n",
        "        unc = torch.sigmoid(self.unc(h))\n",
        "        return mu,sigma,unc\n",
        "\n",
        "class GammaMoE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.router = nn.Conv2d(1, NUM_EXPERTS, 1)\n",
        "        self.experts = nn.ModuleList([CHSN() for _ in range(NUM_EXPERTS)])\n",
        "\n",
        "    def forward(self,x):\n",
        "        w = F.softmax(self.router(x), dim=1)\n",
        "        mu=sigma=unc=0\n",
        "        for i,e in enumerate(self.experts):\n",
        "            m,s,u = e(x)\n",
        "            mu += w[:,i:i+1]*m\n",
        "            sigma += w[:,i:i+1]*s\n",
        "            unc += w[:,i:i+1]*u\n",
        "        return mu,sigma,unc\n",
        "\n",
        "class ImplicitSDE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,1,3,1,1)\n",
        "        )\n",
        "    def forward(self,x,mu,sigma):\n",
        "        return (x + self.net(torch.cat([x,mu,sigma],1))).clamp(EPS,1)\n",
        "\n",
        "class GMiSDENet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.moe = GammaMoE()\n",
        "        self.sde = ImplicitSDE()\n",
        "    def forward(self,x):\n",
        "        mu,sigma,unc = self.moe(x)\n",
        "        return self.sde(x, mu*unc, sigma)\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING\n",
        "# ============================================================\n",
        "\n",
        "def train_model(model, name):\n",
        "    data = MNISTSpeckle(train=True)\n",
        "    loader = DataLoader(data,BATCH,shuffle=True)\n",
        "    model = model.to(DEVICE)\n",
        "    opt = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    print(f\"\\nTraining {name}\")\n",
        "    for ep in range(EPOCHS):\n",
        "        tot=0\n",
        "        for noisy,clean in loader:\n",
        "            noisy=noisy.unsqueeze(1).to(DEVICE)\n",
        "            clean=clean.unsqueeze(1).to(DEVICE)\n",
        "            out=model(noisy)\n",
        "            loss=F.mse_loss(out,clean)\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "            tot+=loss.item()\n",
        "        print(f\"[{name}][{ep+1}] Loss={tot/len(loader):.4f}\")\n",
        "    return model\n",
        "\n",
        "# ============================================================\n",
        "# EVALUATION (FIXED + NOISE MAP)\n",
        "# ============================================================\n",
        "\n",
        "def evaluate(models):\n",
        "    data = MNISTSpeckle(train=False)\n",
        "\n",
        "    psnr_scores = {k:[] for k in models}\n",
        "    ssim_scores = {k:[] for k in models}\n",
        "\n",
        "    for i in range(10):\n",
        "        noisy,clean = data[i]\n",
        "        noisy=noisy.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "        clean=clean.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        cn = clean[0,0].cpu().numpy()\n",
        "        nn = noisy[0,0].cpu().numpy()\n",
        "        noise_map = np.abs(nn - cn)\n",
        "\n",
        "        outputs={}\n",
        "        with torch.no_grad():\n",
        "            for name,m in models.items():\n",
        "                outputs[name] = m(noisy)[0,0].cpu().numpy()\n",
        "\n",
        "        fig,ax=plt.subplots(1,6,figsize=(20,3))\n",
        "        ax[0].imshow(cn,cmap=\"gray\"); ax[0].set_title(\"Clean\")\n",
        "        ax[1].imshow(nn,cmap=\"gray\"); ax[1].set_title(\"Noisy\")\n",
        "        ax[2].imshow(noise_map,cmap=\"gray\"); ax[2].set_title(\"Noise\")\n",
        "\n",
        "        for idx,name in enumerate(models):\n",
        "            p = peak_signal_noise_ratio(cn, outputs[name], data_range=1.0)\n",
        "            s = structural_similarity(cn, outputs[name], data_range=1.0)\n",
        "            psnr_scores[name].append(p)\n",
        "            ssim_scores[name].append(s)\n",
        "\n",
        "            ax[idx+3].imshow(outputs[name],cmap=\"gray\")\n",
        "            ax[idx+3].set_title(f\"{name}\\nPSNR={p:.2f}\\nSSIM={s:.4f}\")\n",
        "\n",
        "        for a in ax: a.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{SAVE_DIR}/sample_{i}.png\", dpi=150)\n",
        "        plt.close()\n",
        "\n",
        "    print(\"\\n=== FINAL RESULTS ===\")\n",
        "    for k in models:\n",
        "        print(f\"{k}: PSNR={np.mean(psnr_scores[k]):.2f}, SSIM={np.mean(ssim_scores[k]):.4f}\")\n",
        "\n",
        "# ============================================================\n",
        "# MAIN\n",
        "# ============================================================\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    models = {\n",
        "        \"GMiSDE\": train_model(GMiSDENet(),\"GMiSDE\"),\n",
        "        \"ID-CNN\": train_model(IDCNN(),\"ID-CNN\"),\n",
        "        \"DnCNN\": train_model(DnCNN(),\"DnCNN\")\n",
        "    }\n",
        "    evaluate(models)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkDAh68h2JNg",
        "outputId": "1666359e-8312-4c1b-f1dd-08f19377d02d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training GMiSDE\n",
            "[GMiSDE][1] Loss=0.0033\n",
            "[GMiSDE][2] Loss=0.0022\n",
            "[GMiSDE][3] Loss=0.0021\n",
            "[GMiSDE][4] Loss=0.0020\n",
            "[GMiSDE][5] Loss=0.0020\n",
            "[GMiSDE][6] Loss=0.0020\n",
            "[GMiSDE][7] Loss=0.0019\n",
            "[GMiSDE][8] Loss=0.0019\n",
            "[GMiSDE][9] Loss=0.0019\n",
            "[GMiSDE][10] Loss=0.0019\n",
            "\n",
            "Training ID-CNN\n",
            "[ID-CNN][1] Loss=0.0040\n",
            "[ID-CNN][2] Loss=0.0025\n",
            "[ID-CNN][3] Loss=0.0024\n",
            "[ID-CNN][4] Loss=0.0023\n",
            "[ID-CNN][5] Loss=0.0023\n",
            "[ID-CNN][6] Loss=0.0022\n",
            "[ID-CNN][7] Loss=0.0022\n",
            "[ID-CNN][8] Loss=0.0022\n",
            "[ID-CNN][9] Loss=0.0022\n",
            "[ID-CNN][10] Loss=0.0021\n",
            "\n",
            "Training DnCNN\n",
            "[DnCNN][1] Loss=0.0033\n",
            "[DnCNN][2] Loss=0.0025\n",
            "[DnCNN][3] Loss=0.0024\n",
            "[DnCNN][4] Loss=0.0023\n",
            "[DnCNN][5] Loss=0.0023\n",
            "[DnCNN][6] Loss=0.0023\n",
            "[DnCNN][7] Loss=0.0022\n",
            "[DnCNN][8] Loss=0.0022\n",
            "[DnCNN][9] Loss=0.0022\n",
            "[DnCNN][10] Loss=0.0022\n",
            "\n",
            "=== FINAL RESULTS ===\n",
            "GMiSDE: PSNR=28.06, SSIM=0.9783\n",
            "ID-CNN: PSNR=27.49, SSIM=0.9749\n",
            "DnCNN: PSNR=27.54, SSIM=0.9753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# GMiSDE-Net vs ID-CNN vs DnCNN\n",
        "# CIFAR-10 (Grayscale) + Gamma Speckle\n",
        "# ============================================================\n",
        "\n",
        "import os, torch, numpy as np, matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "IMG_SIZE = 32\n",
        "BATCH = 32\n",
        "EPOCHS = 15\n",
        "LR = 2e-4\n",
        "\n",
        "EPS = 1e-4\n",
        "GAMMA_K = 2.0\n",
        "NUM_EXPERTS = 4\n",
        "\n",
        "SAVE_DIR = \"./gmisde_cifar_results\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# DATASET: CIFAR-10 → GRAYSCALE + GAMMA SPECKLE\n",
        "# ============================================================\n",
        "\n",
        "class CIFAR10Speckle(Dataset):\n",
        "    def __init__(self, train=True):\n",
        "        tfm = T.Compose([\n",
        "            T.Grayscale(),\n",
        "            T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "            T.ToTensor()\n",
        "        ])\n",
        "        base = datasets.CIFAR10(\n",
        "            \"./data\", train=train, download=True\n",
        "        )\n",
        "        self.data = []\n",
        "\n",
        "        for img, _ in base:\n",
        "            clean = tfm(img).squeeze(0).clamp(EPS, 1.0)\n",
        "            gamma = torch.distributions.Gamma(GAMMA_K, GAMMA_K).sample(clean.shape)\n",
        "            noisy = (clean * gamma).clamp(EPS, 1.0)\n",
        "            self.data.append((noisy, clean))\n",
        "\n",
        "    def __len__(self): return len(self.data)\n",
        "    def __getitem__(self, i): return self.data[i]\n",
        "\n",
        "# ============================================================\n",
        "# BASELINES\n",
        "# ============================================================\n",
        "\n",
        "class IDCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,1,3,1,1)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        return self.net(x).clamp(EPS,1)\n",
        "\n",
        "class DnCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,1,3,1,1)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        return (x - self.net(x)).clamp(EPS,1)\n",
        "\n",
        "# ============================================================\n",
        "# PROPOSED: GammaMoE + CHSN + Implicit SDE\n",
        "# ============================================================\n",
        "\n",
        "class CHSN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Conv2d(1,32,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(32,64,3,1,1), nn.ReLU()\n",
        "        )\n",
        "        self.mu = nn.Conv2d(64,1,3,1,1)\n",
        "        self.sigma = nn.Conv2d(64,1,3,1,1)\n",
        "        self.unc = nn.Conv2d(64,1,3,1,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        h = self.enc(x)\n",
        "        mu = self.mu(h)\n",
        "        sigma = 0.1 * F.softplus(self.sigma(h)) + EPS\n",
        "        unc = torch.sigmoid(self.unc(h))\n",
        "        return mu, sigma, unc\n",
        "\n",
        "class GammaMoE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.router = nn.Conv2d(1, NUM_EXPERTS, 1)\n",
        "        self.experts = nn.ModuleList([CHSN() for _ in range(NUM_EXPERTS)])\n",
        "\n",
        "    def forward(self,x):\n",
        "        w = F.softmax(self.router(x), dim=1)\n",
        "        mu = sigma = unc = 0\n",
        "        for i,e in enumerate(self.experts):\n",
        "            m,s,u = e(x)\n",
        "            mu += w[:,i:i+1] * m\n",
        "            sigma += w[:,i:i+1] * s\n",
        "            unc += w[:,i:i+1] * u\n",
        "        return mu, sigma, unc\n",
        "\n",
        "class ImplicitSDE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,1,3,1,1)\n",
        "        )\n",
        "    def forward(self,x,mu,sigma):\n",
        "        return (x + self.net(torch.cat([x,mu,sigma],1))).clamp(EPS,1)\n",
        "\n",
        "class GMiSDENet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.moe = GammaMoE()\n",
        "        self.sde = ImplicitSDE()\n",
        "    def forward(self,x):\n",
        "        mu,sigma,unc = self.moe(x)\n",
        "        return self.sde(x, mu*unc, sigma)\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING\n",
        "# ============================================================\n",
        "\n",
        "def train_model(model, name):\n",
        "    data = CIFAR10Speckle(train=True)\n",
        "    loader = DataLoader(data, BATCH, shuffle=True)\n",
        "    model = model.to(DEVICE)\n",
        "    opt = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    print(f\"\\nTraining {name}\")\n",
        "    for ep in range(EPOCHS):\n",
        "        tot = 0\n",
        "        for noisy,clean in loader:\n",
        "            noisy = noisy.unsqueeze(1).to(DEVICE)\n",
        "            clean = clean.unsqueeze(1).to(DEVICE)\n",
        "            out = model(noisy)\n",
        "            loss = (\n",
        "                F.mse_loss(out, clean) +\n",
        "                0.2 * ((torch.log(out) - torch.log(clean))**2).mean()\n",
        "            )\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "            tot += loss.item()\n",
        "        print(f\"[{name}][{ep+1}] Loss={tot/len(loader):.4f}\")\n",
        "    return model\n",
        "\n",
        "# ============================================================\n",
        "# EVALUATION (SAFE PLOTTING)\n",
        "# ============================================================\n",
        "\n",
        "def evaluate(models):\n",
        "    data = CIFAR10Speckle(train=False)\n",
        "\n",
        "    psnr_scores = {k:[] for k in models}\n",
        "    ssim_scores = {k:[] for k in models}\n",
        "\n",
        "    for i in range(10):\n",
        "        noisy, clean = data[i]\n",
        "        noisy = noisy.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "        clean = clean.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        clean_np = clean[0,0].cpu().numpy()\n",
        "        noisy_np = noisy[0,0].cpu().numpy()\n",
        "\n",
        "        outputs = {}\n",
        "        with torch.no_grad():\n",
        "            for name,model in models.items():\n",
        "                outputs[name] = model(noisy)\n",
        "\n",
        "        for name,out in outputs.items():\n",
        "            out_np = out[0,0].cpu().numpy()\n",
        "            psnr_scores[name].append(\n",
        "                peak_signal_noise_ratio(clean_np, out_np, data_range=1.0)\n",
        "            )\n",
        "            ssim_scores[name].append(\n",
        "                structural_similarity(clean_np, out_np, data_range=1.0)\n",
        "            )\n",
        "\n",
        "        fig,ax = plt.subplots(1,5,figsize=(16,3))\n",
        "        ax[0].imshow(clean_np,cmap=\"gray\"); ax[0].set_title(\"Clean\")\n",
        "        ax[1].imshow(noisy_np,cmap=\"gray\"); ax[1].set_title(\"Noisy\")\n",
        "\n",
        "        for idx,name in enumerate(models):\n",
        "            ax[idx+2].imshow(outputs[name][0,0].cpu(),cmap=\"gray\")\n",
        "            ax[idx+2].set_title(\n",
        "                f\"{name}\\nPSNR={psnr_scores[name][-1]:.2f}\\n\"\n",
        "                f\"SSIM={ssim_scores[name][-1]:.4f}\"\n",
        "            )\n",
        "\n",
        "        for a in ax: a.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{SAVE_DIR}/sample_{i}.png\", dpi=150)\n",
        "        plt.close()\n",
        "\n",
        "    print(\"\\n=== FINAL RESULTS (CIFAR-10) ===\")\n",
        "    for k in models:\n",
        "        print(\n",
        "            f\"{k}: PSNR={np.mean(psnr_scores[k]):.2f}, \"\n",
        "            f\"SSIM={np.mean(ssim_scores[k]):.4f}\"\n",
        "        )\n",
        "\n",
        "# ============================================================\n",
        "# MAIN\n",
        "# ============================================================\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    models = {\n",
        "        \"GMiSDE\": train_model(GMiSDENet(),\"GMiSDE\"),\n",
        "        \"ID-CNN\": train_model(IDCNN(),\"ID-CNN\"),\n",
        "        \"DnCNN\": train_model(DnCNN(),\"DnCNN\")\n",
        "    }\n",
        "    evaluate(models)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61wbxGEsyxtV",
        "outputId": "0863a7e6-cde1-4054-ebef-816066550c4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 42.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training GMiSDE\n",
            "[GMiSDE][1] Loss=0.0391\n",
            "[GMiSDE][2] Loss=0.0288\n",
            "[GMiSDE][3] Loss=0.0271\n",
            "[GMiSDE][4] Loss=0.0259\n",
            "[GMiSDE][5] Loss=0.0252\n",
            "[GMiSDE][6] Loss=0.0246\n",
            "[GMiSDE][7] Loss=0.0243\n",
            "[GMiSDE][8] Loss=0.0240\n",
            "[GMiSDE][9] Loss=0.0237\n",
            "[GMiSDE][10] Loss=0.0235\n",
            "[GMiSDE][11] Loss=0.0233\n",
            "[GMiSDE][12] Loss=0.0231\n",
            "[GMiSDE][13] Loss=0.0229\n",
            "[GMiSDE][14] Loss=0.0228\n",
            "[GMiSDE][15] Loss=0.0226\n",
            "\n",
            "Training ID-CNN\n",
            "[ID-CNN][1] Loss=0.0463\n",
            "[ID-CNN][2] Loss=0.0338\n",
            "[ID-CNN][3] Loss=0.0320\n",
            "[ID-CNN][4] Loss=0.0301\n",
            "[ID-CNN][5] Loss=0.0287\n",
            "[ID-CNN][6] Loss=0.0278\n",
            "[ID-CNN][7] Loss=0.0281\n",
            "[ID-CNN][8] Loss=0.0267\n",
            "[ID-CNN][9] Loss=0.0267\n",
            "[ID-CNN][10] Loss=0.0264\n",
            "[ID-CNN][11] Loss=0.0259\n",
            "[ID-CNN][12] Loss=0.0256\n",
            "[ID-CNN][13] Loss=0.0255\n",
            "[ID-CNN][14] Loss=0.0252\n",
            "[ID-CNN][15] Loss=0.0250\n",
            "\n",
            "Training DnCNN\n",
            "[DnCNN][1] Loss=0.0434\n",
            "[DnCNN][2] Loss=0.0317\n",
            "[DnCNN][3] Loss=0.0295\n",
            "[DnCNN][4] Loss=0.0290\n",
            "[DnCNN][5] Loss=0.0279\n",
            "[DnCNN][6] Loss=0.0270\n",
            "[DnCNN][7] Loss=0.0267\n",
            "[DnCNN][8] Loss=0.0263\n",
            "[DnCNN][9] Loss=0.0263\n",
            "[DnCNN][10] Loss=0.0257\n",
            "[DnCNN][11] Loss=0.0255\n",
            "[DnCNN][12] Loss=0.0253\n",
            "[DnCNN][13] Loss=0.0251\n",
            "[DnCNN][14] Loss=0.0249\n",
            "[DnCNN][15] Loss=0.0247\n",
            "\n",
            "=== FINAL RESULTS (CIFAR-10) ===\n",
            "GMiSDE: PSNR=20.38, SSIM=0.5861\n",
            "ID-CNN: PSNR=20.15, SSIM=0.5806\n",
            "DnCNN: PSNR=20.11, SSIM=0.5806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# GMiSDE-Net Robustness Study\n",
        "# CIFAR-10 (Grayscale) + Gamma Speckle\n",
        "# Gamma values: k = [2,4,6,8,10]\n",
        "# ============================================================\n",
        "\n",
        "import os, torch, numpy as np, matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "IMG_SIZE = 32\n",
        "BATCH = 32\n",
        "EPOCHS = 12\n",
        "LR = 2e-4\n",
        "\n",
        "EPS = 1e-4\n",
        "NUM_EXPERTS = 4\n",
        "\n",
        "TRAIN_GAMMA = 4.0\n",
        "TEST_GAMMAS = [2, 4, 6, 8, 10]\n",
        "\n",
        "SAVE_DIR = \"./gamma_robustness_cifar\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# DATASET\n",
        "# ============================================================\n",
        "\n",
        "class CIFAR10Speckle(Dataset):\n",
        "    def __init__(self, gamma_k, train=True):\n",
        "        self.gamma_k = gamma_k\n",
        "        tfm = T.Compose([\n",
        "            T.Grayscale(),\n",
        "            T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "            T.ToTensor()\n",
        "        ])\n",
        "\n",
        "        base = datasets.CIFAR10(\"./data\", train=train, download=True)\n",
        "        self.samples = []\n",
        "\n",
        "        for img, _ in base:\n",
        "            clean = tfm(img).squeeze(0).clamp(EPS, 1.0)\n",
        "            gamma = torch.distributions.Gamma(gamma_k, gamma_k).sample(clean.shape)\n",
        "            noisy = (clean * gamma).clamp(EPS, 1.0)\n",
        "            self.samples.append((noisy, clean))\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, i): return self.samples[i]\n",
        "\n",
        "# ============================================================\n",
        "# PROPOSED MODEL: GMiSDE-Net\n",
        "# ============================================================\n",
        "\n",
        "class CHSN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Conv2d(1,32,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(32,64,3,1,1), nn.ReLU()\n",
        "        )\n",
        "        self.mu = nn.Conv2d(64,1,3,1,1)\n",
        "        self.sigma = nn.Conv2d(64,1,3,1,1)\n",
        "        self.unc = nn.Conv2d(64,1,3,1,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        h = self.enc(x)\n",
        "        mu = self.mu(h)\n",
        "        sigma = 0.1 * F.softplus(self.sigma(h)) + EPS\n",
        "        unc = torch.sigmoid(self.unc(h))\n",
        "        return mu, sigma, unc\n",
        "\n",
        "class GammaMoE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.router = nn.Conv2d(1, NUM_EXPERTS, 1)\n",
        "        self.experts = nn.ModuleList([CHSN() for _ in range(NUM_EXPERTS)])\n",
        "\n",
        "    def forward(self,x):\n",
        "        w = F.softmax(self.router(x), dim=1)\n",
        "        mu = sigma = unc = 0\n",
        "        for i,e in enumerate(self.experts):\n",
        "            m,s,u = e(x)\n",
        "            mu += w[:,i:i+1] * m\n",
        "            sigma += w[:,i:i+1] * s\n",
        "            unc += w[:,i:i+1] * u\n",
        "        return mu, sigma, unc\n",
        "\n",
        "class ImplicitSDE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,1,3,1,1)\n",
        "        )\n",
        "    def forward(self,x,mu,sigma):\n",
        "        return (x + self.net(torch.cat([x,mu,sigma],1))).clamp(EPS,1)\n",
        "\n",
        "class GMiSDENet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.moe = GammaMoE()\n",
        "        self.sde = ImplicitSDE()\n",
        "    def forward(self,x):\n",
        "        mu,sigma,unc = self.moe(x)\n",
        "        return self.sde(x, mu*unc, sigma)\n",
        "\n",
        "# ============================================================\n",
        "# TRAINING (single Gamma)\n",
        "# ============================================================\n",
        "\n",
        "def train_model():\n",
        "    dataset = CIFAR10Speckle(TRAIN_GAMMA, train=True)\n",
        "    loader = DataLoader(dataset, BATCH, shuffle=True)\n",
        "\n",
        "    model = GMiSDENet().to(DEVICE)\n",
        "    opt = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    print(f\"\\nTraining GMiSDE-Net (Gamma={TRAIN_GAMMA})\\n\")\n",
        "\n",
        "    for ep in range(EPOCHS):\n",
        "        tot = 0\n",
        "        for noisy,clean in loader:\n",
        "            noisy = noisy.unsqueeze(1).to(DEVICE)\n",
        "            clean = clean.unsqueeze(1).to(DEVICE)\n",
        "\n",
        "            out = model(noisy)\n",
        "            loss = (\n",
        "                F.mse_loss(out, clean) +\n",
        "                0.2 * ((torch.log(out) - torch.log(clean))**2).mean()\n",
        "            )\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            tot += loss.item()\n",
        "\n",
        "        print(f\"[Epoch {ep+1:02d}] Loss={tot/len(loader):.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# ============================================================\n",
        "# EVALUATION ACROSS GAMMA VALUES\n",
        "# ============================================================\n",
        "\n",
        "def evaluate_gamma_robustness(model):\n",
        "    results = {}\n",
        "\n",
        "    for k in TEST_GAMMAS:\n",
        "        dataset = CIFAR10Speckle(k, train=False)\n",
        "        psnr_list, ssim_list = [], []\n",
        "\n",
        "        for i in range(100):\n",
        "            noisy, clean = dataset[i]\n",
        "            noisy = noisy.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "            clean = clean.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                recon = model(noisy)\n",
        "\n",
        "            cn = clean[0,0].cpu().numpy()\n",
        "            rn = recon[0,0].cpu().numpy()\n",
        "\n",
        "            psnr_list.append(peak_signal_noise_ratio(cn, rn, data_range=1.0))\n",
        "            ssim_list.append(structural_similarity(cn, rn, data_range=1.0))\n",
        "\n",
        "        results[k] = (np.mean(psnr_list), np.mean(ssim_list))\n",
        "        print(f\"Gamma {k}: PSNR={results[k][0]:.2f}, SSIM={results[k][1]:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# ============================================================\n",
        "# MAIN\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = train_model()\n",
        "    gamma_results = evaluate_gamma_robustness(model)\n",
        "\n",
        "    # Plot\n",
        "    ks = list(gamma_results.keys())\n",
        "    psnrs = [gamma_results[k][0] for k in ks]\n",
        "    ssims = [gamma_results[k][1] for k in ks]\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(ks, psnrs, marker=\"o\", label=\"PSNR\")\n",
        "    plt.plot(ks, ssims, marker=\"s\", label=\"SSIM\")\n",
        "    plt.xlabel(\"Gamma Shape Parameter k\")\n",
        "    plt.ylabel(\"Metric Value\")\n",
        "    plt.title(\"GMiSDE-Net Robustness to Gamma Mismatch\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f\"{SAVE_DIR}/gamma_robustness_curve.png\", dpi=150)\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMspi1_F8BW2",
        "outputId": "148f24d1-0c5d-4bcd-db47-41aa44cf6da1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training GMiSDE-Net (Gamma=4.0)\n",
            "\n",
            "[Epoch 01] Loss=0.0282\n",
            "[Epoch 02] Loss=0.0195\n",
            "[Epoch 03] Loss=0.0181\n",
            "[Epoch 04] Loss=0.0172\n",
            "[Epoch 05] Loss=0.0171\n",
            "[Epoch 06] Loss=0.0162\n",
            "[Epoch 07] Loss=0.0160\n",
            "[Epoch 08] Loss=0.0155\n",
            "[Epoch 09] Loss=0.0155\n",
            "[Epoch 10] Loss=0.0153\n",
            "[Epoch 11] Loss=0.0152\n",
            "[Epoch 12] Loss=0.0149\n",
            "Gamma 2: PSNR=19.07, SSIM=0.5988\n",
            "Gamma 4: PSNR=22.29, SSIM=0.7226\n",
            "Gamma 6: PSNR=22.89, SSIM=0.7501\n",
            "Gamma 8: PSNR=23.12, SSIM=0.7549\n",
            "Gamma 10: PSNR=23.14, SSIM=0.7560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Ablation Study: Sensitivity to Loss Constants (α, β)\n",
        "# GMiSDE-Net | CIFAR-10 + Gamma Speckle\n",
        "# ============================================================\n",
        "\n",
        "import torch, numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "IMG_SIZE = 32\n",
        "BATCH = 32\n",
        "EPOCHS = 5          # SHORT: ablation only\n",
        "LR = 2e-4\n",
        "\n",
        "EPS = 1e-4\n",
        "GAMMA_K = 4.0\n",
        "NUM_EXPERTS = 4\n",
        "\n",
        "ALPHAS = [0.0, 0.1, 0.2, 0.4]\n",
        "BETAS  = [0.0, 0.05, 0.1]\n",
        "\n",
        "# ============================================================\n",
        "# DATASET\n",
        "# ============================================================\n",
        "\n",
        "class CIFAR10Speckle(Dataset):\n",
        "    def __init__(self, train=True):\n",
        "        tfm = T.Compose([\n",
        "            T.Grayscale(),\n",
        "            T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "            T.ToTensor()\n",
        "        ])\n",
        "        base = datasets.CIFAR10(\"./data\", train=train, download=True)\n",
        "        self.data = []\n",
        "\n",
        "        for img,_ in base:\n",
        "            clean = tfm(img).squeeze(0).clamp(EPS,1.0)\n",
        "            gamma = torch.distributions.Gamma(GAMMA_K, GAMMA_K).sample(clean.shape)\n",
        "            noisy = (clean * gamma).clamp(EPS,1.0)\n",
        "            self.data.append((noisy, clean))\n",
        "\n",
        "    def __len__(self): return len(self.data)\n",
        "    def __getitem__(self,i): return self.data[i]\n",
        "\n",
        "# ============================================================\n",
        "# MODEL (compact)\n",
        "# ============================================================\n",
        "\n",
        "class CHSN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.f = nn.Sequential(\n",
        "            nn.Conv2d(1,32,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(32,64,3,1,1), nn.ReLU()\n",
        "        )\n",
        "        self.mu = nn.Conv2d(64,1,3,1,1)\n",
        "        self.sg = nn.Conv2d(64,1,3,1,1)\n",
        "        self.unc = nn.Conv2d(64,1,3,1,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        h = self.f(x)\n",
        "        return self.mu(h), 0.1*F.softplus(self.sg(h))+EPS, torch.sigmoid(self.unc(h))\n",
        "\n",
        "class GMiSDENet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.router = nn.Conv2d(1, NUM_EXPERTS, 1)\n",
        "        self.experts = nn.ModuleList([CHSN() for _ in range(NUM_EXPERTS)])\n",
        "        self.sde = nn.Sequential(\n",
        "            nn.Conv2d(3,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,1,3,1,1)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        w = torch.softmax(self.router(x), dim=1)\n",
        "        mu = sg = uc = 0\n",
        "        for i,e in enumerate(self.experts):\n",
        "            m,s,u = e(x)\n",
        "            mu += w[:,i:i+1]*m\n",
        "            sg += w[:,i:i+1]*s\n",
        "            uc += w[:,i:i+1]*u\n",
        "        delta = self.sde(torch.cat([x,mu*uc,sg],1))\n",
        "        return (x+delta).clamp(EPS,1.0), uc\n",
        "\n",
        "# ============================================================\n",
        "# TRAIN + EVAL (single run)\n",
        "# ============================================================\n",
        "\n",
        "def run_experiment(alpha, beta):\n",
        "    train_data = CIFAR10Speckle(train=True)\n",
        "    test_data  = CIFAR10Speckle(train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_data, BATCH, shuffle=True)\n",
        "    model = GMiSDENet().to(DEVICE)\n",
        "    opt = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    # ---- training ----\n",
        "    for _ in range(EPOCHS):\n",
        "        for noisy, clean in train_loader:\n",
        "            noisy = noisy.unsqueeze(1).to(DEVICE)\n",
        "            clean = clean.unsqueeze(1).to(DEVICE)\n",
        "\n",
        "            out, unc = model(noisy)\n",
        "\n",
        "            mse = F.mse_loss(out, clean)\n",
        "            log_loss = ((torch.log(out)-torch.log(clean))**2).mean()\n",
        "            unc_reg = unc.mean()\n",
        "\n",
        "            loss = mse + alpha*log_loss + beta*unc_reg\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "    # ---- evaluation ----\n",
        "    psnr, ssim = [], []\n",
        "    for i in range(50):\n",
        "        noisy, clean = test_data[i]\n",
        "        noisy = noisy.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "        clean = clean.unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out,_ = model(noisy)\n",
        "\n",
        "        c = clean[0,0].cpu().numpy()\n",
        "        r = out[0,0].cpu().numpy()\n",
        "\n",
        "        psnr.append(peak_signal_noise_ratio(c,r,data_range=1.0))\n",
        "        ssim.append(structural_similarity(c,r,data_range=1.0))\n",
        "\n",
        "    return np.mean(psnr), np.mean(ssim)\n",
        "\n",
        "# ============================================================\n",
        "# ABLATION LOOP\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n=== CONSTANT SENSITIVITY ABLATION ===\\n\")\n",
        "    print(\" alpha | beta  |  PSNR  |  SSIM \")\n",
        "    print(\"----------------------------------\")\n",
        "\n",
        "    for a in ALPHAS:\n",
        "        for b in BETAS:\n",
        "            p,s = run_experiment(a,b)\n",
        "            print(f\" {a:4.2f} | {b:4.2f} | {p:6.2f} | {s:6.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th0w08Sm-V7g",
        "outputId": "e4d88039-0fd9-4e22-a0a7-7df0b69bea47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== CONSTANT SENSITIVITY ABLATION ===\n",
            "\n",
            " alpha | beta  |  PSNR  |  SSIM \n",
            "----------------------------------\n",
            " 0.00 | 0.00 |  22.04 | 0.7261\n",
            " 0.00 | 0.05 |  21.73 | 0.7112\n",
            " 0.00 | 0.10 |  21.78 | 0.7109\n",
            " 0.10 | 0.00 |  21.84 | 0.7152\n",
            " 0.10 | 0.05 |  21.45 | 0.7143\n",
            " 0.10 | 0.10 |  21.56 | 0.7070\n",
            " 0.20 | 0.00 |  21.77 | 0.7133\n",
            " 0.20 | 0.05 |  21.59 | 0.7169\n",
            " 0.20 | 0.10 |  21.45 | 0.7097\n",
            " 0.40 | 0.00 |  21.48 | 0.7188\n",
            " 0.40 | 0.05 |  21.36 | 0.7047\n",
            " 0.40 | 0.10 |  21.22 | 0.7100\n"
          ]
        }
      ]
    }
  ]
}